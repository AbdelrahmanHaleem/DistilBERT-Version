{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdelrahmanHaleem/DistilBERT-Version/blob/main/Untitled23_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkFi5Vcix665"
      },
      "outputs": [],
      "source": [
        "# ====== Cell 1: ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª ÙˆØ¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ======\n",
        "# Ø´ØºÙ‘Ù„ Ø§Ù„Ø®Ù„ÙŠØ© ÙƒØ§Ù…Ù„Ø© ÙÙŠ Colab\n",
        "!pip install -q transformers datasets accelerate evaluate\n",
        "\n",
        "# Ø¥Ù† ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… Google Drive Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§ØªØŒ ÙÙƒÙ‘Ø± ØªØ±Ø¨Ø·Ù‡:\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "import os, json, re, math, statistics\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import DistilBertTokenizerFast\n",
        "\n",
        "# ------------ ØªØ¹Ø¯ÙŠÙ„ Ù‡Ø°Ù‡ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø­Ø³Ø¨ Ø¨ÙŠØ¦ØªÙƒ ------------\n",
        "# Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ù€ Excel (ØºÙŠÙ‘Ø±Ù‡ Ù„Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­ ÙÙŠ Colab/Drive)\n",
        "EXCEL_PATH = \"/content/XSS_Data_balanced.xlsx\"\n",
        "\n",
        "# Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø®Ø±Ø¬ Ù„Ø­ÙØ¸ Ø§Ù„ØªØ­Ø¶ÙŠØ±Ø§Øª ÙˆØ§Ù„Ù€ datasets\n",
        "OUT_DIR = \"/content/prepared_xss_for_distilbert\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬/tokenizer\n",
        "MODEL_NAME = \"distilbert-base-uncased\"   # Ø£Ùˆ \"distilbert-base-multilingual-cased\" Ù„Ùˆ Ù„ØºØ§Øª Ù…Ø®ØªÙ„Ø·Ø©\n",
        "MAX_LENGTH = 512                     # Ø¬Ø±Ù‘Ø¨ 256 Ø£ÙˆÙ„Ø§Ù‹Ø› Ø§Ø±ÙØ¹ Ù„Ù€512 Ù„Ùˆ Ø§Ù„Ø°Ø§ÙƒØ±Ø© ØªØ³Ù…Ø­\n",
        "TRUNCATION_STRAT = \"only_second\"          # Ø®ÙŠØ§Ø±Ø§Øª: \"only_second\", \"longest_first\"\n",
        "RANDOM_SEED = 42\n",
        "TEST_SIZE = 0.1\n",
        "VAL_SIZE = 0.1\n",
        "# ---------------------------------------------------\n",
        "\n",
        "print(\"Config:\", EXCEL_PATH, OUT_DIR, MODEL_NAME, MAX_LENGTH, TRUNCATION_STRAT)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Cell 2: Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù ÙˆØ§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ======\n",
        "df = pd.read_excel(EXCEL_PATH)\n",
        "print(\"Loaded shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "# heuristics Ù„Ø§Ø®ØªÙŠØ§Ø± Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù†Øµ ÙˆØ§Ù„Ù€ label (Ù„Ùˆ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ØºÙŠØ± Ù‚ÙŠØ§Ø³ÙŠØ©)\n",
        "possible_text_cols = [c for c in df.columns if any(k in c.lower() for k in (\"text\",\"payload\",\"input\",\"attack\",\"sample\",\"sentence\",\"request\"))]\n",
        "possible_label_cols = [c for c in df.columns if any(k in c.lower() for k in (\"label\",\"target\",\"class\",\"y\",\"is_xss\",\"normal\",\"malicious\"))]\n",
        "\n",
        "text_col = possible_text_cols[0] if possible_text_cols else df.columns[0]\n",
        "label_col = possible_label_cols[0] if possible_label_cols else (df.columns[1] if len(df.columns)>1 else None)\n",
        "\n",
        "print(\"Using text_col:\", text_col, \"label_col:\", label_col)\n",
        "df = df.rename(columns={text_col:\"text\"})\n",
        "if label_col:\n",
        "    df = df.rename(columns={label_col:\"label\"})\n",
        "else:\n",
        "    # Ù„Ùˆ Ù…ÙÙŠØ´ label Ø§Ù…Ù„Ø£ Ø¨ØµÙØ± (ØºÙŠØ± Ù…Ø±ØºÙˆØ¨ ÙˆÙ„ÙƒÙ† fallback)\n",
        "    df[\"label\"] = 0\n",
        "    print(\"No label column found -> created dummy label=0\")\n",
        "\n",
        "# ØªÙ†Ø¸ÙŠÙ Ø¨Ø³ÙŠØ·\n",
        "df = df.dropna(subset=[\"text\",\"label\"])\n",
        "df[\"raw_text\"] = df[\"text\"].astype(str)   # Ù†Ø­ÙØ¸ Ø§Ù„Ø£ØµÙ„ ÙƒÙ…Ø§ Ù‡Ùˆ\n",
        "df[\"label\"] = pd.to_numeric(df[\"label\"], errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "print(\"Final shape after clean:\", df.shape)\n",
        "print(\"Class distribution:\\n\", df[\"label\"].value_counts())\n"
      ],
      "metadata": {
        "id": "LjoJmAr6ydrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Cell 3: Ø¥Ù†Ø´Ø§Ø¡ enc_a Ùˆ enc_b Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù€ XSS ÙƒÙ…Ø§ Ø·Ù„Ø¨Øª ======\n",
        "def enc_a_fn(s):\n",
        "    s = str(s).replace(\"\\r\",\" \").replace(\"\\n\",\" \").strip()\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s  # minimal normalization, keep payload chars\n",
        "\n",
        "def normalize_for_b(s):\n",
        "    s2 = str(s).replace(\"\\r\",\" \").replace(\"\\n\",\" \").strip()\n",
        "    s2 = re.sub(r\"\\s+\", \" \", s2)\n",
        "    return s2.lower()\n",
        "\n",
        "def enc_b_fn(row):\n",
        "    if int(row[\"label\"]) == 1:\n",
        "        # IMPORTANT: preserve payload exactly, only add marker prefix\n",
        "        return \"<XSS_RAW> \" + row[\"raw_text\"]\n",
        "    else:\n",
        "        return \"<NORMAL> \" + normalize_for_b(row[\"raw_text\"])\n",
        "\n",
        "df[\"enc_a\"] = df[\"raw_text\"].apply(enc_a_fn)\n",
        "df[\"enc_b\"] = df.apply(enc_b_fn, axis=1)\n",
        "\n",
        "# Ø¹Ø±Ø¶ Ø£Ù…Ø«Ù„Ø© Ù„Ù„ØªØ£ÙƒØ¯\n",
        "display(df[[\"raw_text\",\"label\",\"enc_a\",\"enc_b\"]].head(6))\n"
      ],
      "metadata": {
        "id": "BzGDmWw6yeNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Cell 4: ØªÙ‚Ø³ÙŠÙ… stratified Ø¥Ù„Ù‰ train/val/test ÙˆØ­ÙØ¸ ÙƒÙ€ JSONL Ù„Ù„Ù…Ø±Ø¬Ø¹ ======\n",
        "train_val_df, test_df = train_test_split(df, test_size=TEST_SIZE, stratify=df[\"label\"], random_state=RANDOM_SEED)\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=VAL_SIZE/(1-TEST_SIZE), stratify=train_val_df[\"label\"], random_state=RANDOM_SEED)\n",
        "\n",
        "print(\"Sizes:\", len(train_df), len(val_df), len(test_df))\n",
        "\n",
        "# Ø­ÙØ¸ JSONL (Ø®Ø¯Ù…Ø© Ù„Ù„Ø±Ø¬ÙˆØ¹ Ù„Ù„Ù€ raw Ø¥Ø°Ø§ Ø§Ø­ØªØ¬Øª)\n",
        "def save_jsonl(df_in, path):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for _, row in df_in.iterrows():\n",
        "            rec = {\n",
        "                \"raw_text\": row[\"raw_text\"],\n",
        "                \"enc_a\": row[\"enc_a\"],\n",
        "                \"enc_b\": row[\"enc_b\"],\n",
        "                \"label\": int(row[\"label\"])\n",
        "            }\n",
        "            f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "save_jsonl(train_df, os.path.join(OUT_DIR, \"train.jsonl\"))\n",
        "save_jsonl(val_df,   os.path.join(OUT_DIR, \"val.jsonl\"))\n",
        "save_jsonl(test_df,  os.path.join(OUT_DIR, \"test.jsonl\"))\n",
        "print(\"Saved JSONL files to\", OUT_DIR)\n"
      ],
      "metadata": {
        "id": "8xBkrLElygQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Cell 5: Ø¨Ù†Ø§Ø¡ HF Dataset ÙˆØªÙˆÙƒÙ†ÙŠØ²ÙŠØ´Ù† ÙƒÙ€ sentence-pair ======\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def df_to_hf(ds_df):\n",
        "    return Dataset.from_pandas(ds_df[[\"enc_a\",\"enc_b\",\"label\",\"raw_text\"]].reset_index(drop=True))\n",
        "\n",
        "hf_train = df_to_hf(train_df)\n",
        "hf_val   = df_to_hf(val_df)\n",
        "hf_test  = df_to_hf(test_df)\n",
        "ds = DatasetDict({\"train\": hf_train, \"validation\": hf_val, \"test\": hf_test})\n",
        "\n",
        "def tokenize_pair(batch):\n",
        "    # enc_a -> text, enc_b -> text_pair\n",
        "    return tokenizer(batch[\"enc_a\"], batch[\"enc_b\"],\n",
        "                     truncation=True,\n",
        "                     max_length=MAX_LENGTH,\n",
        "                     padding=False)  # dynamic padding later in data_collator\n",
        "\n",
        "# map tokenize (batched)\n",
        "ds_tokenized = ds.map(tokenize_pair, batched=True, remove_columns=[\"enc_a\",\"enc_b\"])\n",
        "print(\"Tokenization done. Example keys:\", ds_tokenized[\"train\"].column_names)\n",
        "\n",
        "# Ø­Ø³Ø§Ø¨ Ø§Ø­ØµØ§Ø¡Ø§Øª Ø£Ø·ÙˆØ§Ù„ Ø§Ù„ØªÙˆÙƒÙ†Ø² Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ø§Ø®ØªÙŠØ§Ø± max_length Ù„Ø§Ø­Ù‚Ù‹Ø§\n",
        "def token_length_stats(hf_dataset):\n",
        "    lens = [len(x) for x in hf_dataset[\"input_ids\"]]\n",
        "    return {\n",
        "        \"count\": len(lens),\n",
        "        \"mean\": float(sum(lens)/len(lens)),\n",
        "        \"median\": int(sorted(lens)[len(lens)//2]),\n",
        "        \"max\": max(lens),\n",
        "        \"p90\": int(sorted(lens)[int(0.9*len(lens))-1])\n",
        "    }\n",
        "\n",
        "print(\"Train token lengths:\", token_length_stats(ds_tokenized[\"train\"]))\n",
        "print(\"Val token lengths:\", token_length_stats(ds_tokenized[\"validation\"]))\n",
        "print(\"Test token lengths:\", token_length_stats(ds_tokenized[\"test\"]))\n",
        "\n",
        "# Ø­ÙØ¸ dataset Ù„Ù„Ù€ Trainer Ù„Ø§Ø­Ù‚Ù‹Ø§\n",
        "TOKENIZED_OUT = os.path.join(OUT_DIR, \"hf_tokenized_pair\")\n",
        "ds_tokenized.save_to_disk(TOKENIZED_OUT)\n",
        "print(\"Saved tokenized dataset to:\", TOKENIZED_OUT)\n"
      ],
      "metadata": {
        "id": "AkGcdT4Pyhrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Cell 1: ØªØ«Ø¨ÙŠØª ÙˆØ§Ø³ØªÙŠØ±Ø§Ø¯ (Ù„Ùˆ Ù„Ù… ØªØ«Ø¨Øª Ù…Ù† Ù‚Ø¨Ù„) ======\n",
        "!pip install -q transformers datasets accelerate evaluate\n",
        "\n",
        "from datasets import load_from_disk\n",
        "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# ------------ ØªØ¹Ø¯ÙŠÙ„ Ù‡Ø°Ù‡ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø­Ø³Ø¨ Ø­Ø§Ø¬ØªÙƒ ------------\n",
        "TOKENIZED_OUT = \"/content/prepared_xss_for_distilbert/hf_tokenized_pair\"  # Ù†ÙØ³ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù„ÙŠ Ø­ÙØ¸Øª ÙÙŠÙ‡\n",
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "OUTPUT_DIR = \"/content/xss_distilbert_checkpoints\"\n",
        "NUM_EPOCHS = 3\n",
        "BATCH_SIZE = 16           # Ø¹Ø¯Ù‘Ù„ Ù„Ùˆ Ø¹Ù†Ø¯Ùƒ VRAM Ø£ÙƒØ¨Ø±\n",
        "LR = 2e-5\n",
        "WEIGHT_DECAY = 0.01\n",
        "# -------------------------------------------------------\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "2aR7ux4zyjJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Cell 2: ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù€ dataset ÙˆØ§Ù„Ù€ model ======\n",
        "ds = load_from_disk(TOKENIZED_OUT)\n",
        "print(\"Loaded dataset splits:\", ds.keys())\n",
        "# Ø§Ø·Ø¨Ø¹ Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø­Ø¬Ø§Ù…\n",
        "for k in ds:\n",
        "    print(k, len(ds[k]))\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_NAME)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "id": "i4rrN07JzlP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Cell 3: Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ ======\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "    p, r, f1, _ = precision_recall_fscore_support(labels, preds, average='binary', pos_label=1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f1}\n"
      ],
      "metadata": {
        "id": "hW1boIXuznE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Cell 4: Ø­Ø³Ø§Ø¨ class weights (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) ======\n",
        "# Ù„Ùˆ Ø£Ø±Ø¯Øª Ø§Ø³ØªØ®Ø¯Ø§Ù… class weights Ø¯Ø§Ø®Ù„ loss ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¶Ø§ÙØªÙ‡Ø§ Ø¹Ø¨Ø± ØªØ¹Ø¯ÙŠÙ„ compute_loss ÙÙŠ subclass Trainer.\n",
        "# Ù‡Ù†Ø§ Ù†Ø­Ø³Ø¨Ù‡Ø§ ÙˆÙ†Ø·Ø¨Ø¹Ù‡Ø§ Ù„Ù„Ø±Ø¬ÙˆØ¹ Ø¥Ù„ÙŠÙ‡Ø§ ÙÙ‚Ø·:\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "labels_all = np.concatenate([np.array(ds[\"train\"][\"label\"]), np.array(ds[\"validation\"][\"label\"])])\n",
        "classes = np.unique(labels_all)\n",
        "cw = compute_class_weight(\"balanced\", classes=classes, y=labels_all)\n",
        "class_weights = {int(c): float(w) for c,w in zip(classes, cw)}\n",
        "print(\"Class weights:\", class_weights)\n",
        "# Ù…Ù„Ø§Ø­Ø¸Ø©: DistilBERT default loss Ù„Ø§ ÙŠØ£Ø®Ø° class_weightsØŒ ØªØ­ØªØ§Ø¬ ØªØ¹Ø¯ÙŠÙ„ model.compute_loss Ø£Ùˆ custom Trainer Ø¥Ø°Ø§ Ø£Ø±Ø¯Øª Ø§Ø³ØªØ¹Ù…Ø§Ù„Ù‡Ø§.\n"
      ],
      "metadata": {
        "id": "lXiXDAFozq0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== TrainingArguments fixed for legacy transformers ======\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import torch, inspect, os\n",
        "\n",
        "training_kwargs = dict(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    eval_steps=500,\n",
        "    save_steps=500,\n",
        "    logging_steps=100,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE*2,\n",
        "    learning_rate=LR,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    save_total_limit=3,\n",
        "    fp16=torch.cuda.is_available(),  # Ø§Ø³ØªØ®Ø¯Ù… fp16 Ù„Ùˆ Ø§Ù„Ù€ GPU ÙŠØ¯Ø¹Ù…\n",
        ")\n",
        "\n",
        "sig = inspect.signature(TrainingArguments.__init__)\n",
        "accepted = set(sig.parameters.keys())\n",
        "accepted.discard('self')\n",
        "accepted.discard('kwargs')\n",
        "\n",
        "filtered_kwargs = {k: v for k, v in training_kwargs.items() if k in accepted}\n",
        "\n",
        "print(\"TrainingArguments will be created with keys:\", list(filtered_kwargs.keys()))\n",
        "training_args = TrainingArguments(**filtered_kwargs)\n",
        "\n",
        "# Trainer (Ø¨Ø¯ÙˆÙ† load_best_model_at_end Ø¹Ù„Ø´Ø§Ù† Ù†ØªÙØ§Ø¯Ù‰ Ø§Ù„ØªØ¹Ø§Ø±Ø¶)\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=ds[\"train\"],\n",
        "    eval_dataset=ds[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "print(\"ğŸš€ Starting training ...\")\n",
        "trainer.train()\n",
        "\n",
        "# Save the final model\n",
        "final_path = os.path.join(OUTPUT_DIR, \"final_model\")\n",
        "trainer.save_model(final_path)\n",
        "print(\"âœ… Training finished. Model saved to:\", final_path)"
      ],
      "metadata": {
        "id": "4Bf7pInIztiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Cell 7: ØªÙ‚ÙŠÙŠÙ… Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ======\n",
        "res = trainer.evaluate(ds[\"test\"])\n",
        "print(\"Test eval:\", res)"
      ],
      "metadata": {
        "id": "QhvRkQflzw6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# ğŸ” Full Dataset Sanity Check & Evaluation\n",
        "# ============================================\n",
        "from datasets import load_from_disk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# === Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ===\n",
        "TOKENIZED_OUT = \"/content/prepared_xss_for_distilbert/hf_tokenized_pair\"  # Ø¹Ø¯Ù‘Ù„ Ø­Ø³Ø¨ Ù…Ø³Ø§Ø±Ùƒ\n",
        "ds = load_from_disk(TOKENIZED_OUT)\n",
        "\n",
        "# === 1) Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø¯Ø§Ø®Ù„ ÙƒÙ„ split ===\n",
        "print(\"===== DUPLICATE CHECK =====\")\n",
        "for split in [\"train\", \"validation\", \"test\"]:\n",
        "    texts = pd.Series(ds[split][\"raw_text\"])\n",
        "    dup_count = texts.duplicated().sum()\n",
        "    print(f\"{split}: {dup_count} duplicated rows\")\n",
        "\n",
        "# === 2) Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª / Ø§Ù„ØªØ³Ø±ÙŠØ¨ Ø¨ÙŠÙ† Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª ===\n",
        "print(\"\\n===== INTERSECTION CHECK =====\")\n",
        "train_texts = pd.Series(ds[\"train\"][\"raw_text\"])\n",
        "val_texts   = pd.Series(ds[\"validation\"][\"raw_text\"])\n",
        "test_texts  = pd.Series(ds[\"test\"][\"raw_text\"])\n",
        "\n",
        "overlap_tv  = train_texts.isin(val_texts).sum()\n",
        "overlap_tt  = train_texts.isin(test_texts).sum()\n",
        "overlap_vt  = val_texts.isin(test_texts).sum()\n",
        "\n",
        "print(f\"Train âˆ© Validation: {overlap_tv}\")\n",
        "print(f\"Train âˆ© Test: {overlap_tt}\")\n",
        "print(f\"Validation âˆ© Test: {overlap_vt}\")\n",
        "\n",
        "# Ø§Ø·Ø¨Ø¹ Ù…Ø«Ø§Ù„ Ù„Ùˆ ÙÙŠ overlap\n",
        "if overlap_tt > 0:\n",
        "    print(\"\\nâš ï¸ Example of train/test overlap:\")\n",
        "    print(train_texts[train_texts.isin(test_texts)].iloc[0])\n",
        "\n",
        "# === 3) ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¹Ù„Ù‰ test set ===\n",
        "print(\"\\n===== MODEL PERFORMANCE =====\")\n",
        "pred_output = trainer.predict(ds[\"test\"])\n",
        "logits = pred_output.predictions\n",
        "preds = np.argmax(logits, axis=1)\n",
        "labels = pred_output.label_ids\n",
        "\n",
        "print(classification_report(labels, preds, digits=4))\n",
        "cm = confusion_matrix(labels, preds)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# === 4) Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¹ÙŠÙ†Ø§Øª Ø®Ø§Ø·Ø¦Ø© (FP / FN) ===\n",
        "test_raws = ds[\"test\"][\"raw_text\"]\n",
        "df_res = pd.DataFrame({\n",
        "    \"raw\": test_raws,\n",
        "    \"label\": labels,\n",
        "    \"pred\": preds\n",
        "})\n",
        "\n",
        "fn = df_res[(df_res.label == 1) & (df_res.pred == 0)]\n",
        "fp = df_res[(df_res.label == 0) & (df_res.pred == 1)]\n",
        "\n",
        "print(\"\\n===== SAMPLE FALSE NEGATIVES =====\")\n",
        "print(fn.head(5).to_dict(orient=\"records\"))\n",
        "\n",
        "print(\"\\n===== SAMPLE FALSE POSITIVES =====\")\n",
        "print(fp.head(5).to_dict(orient=\"records\"))\n",
        "\n",
        "# === 5) Ù…Ù„Ø®Øµ Ù†Ù‡Ø§Ø¦ÙŠ ===\n",
        "if overlap_tt > 0 or overlap_tv > 0 or overlap_vt > 0:\n",
        "    print(\"\\nâš ï¸ WARNING: Dataset leakage detected between splits!\")\n",
        "elif fn.empty and fp.empty:\n",
        "    print(\"\\nâœ… Perfect predictions and no misclassifications detected.\")\n",
        "else:\n",
        "    print(\"\\nâ„¹ï¸ Model shows some misclassifications, check FP/FN samples above.\")\n"
      ],
      "metadata": {
        "id": "SSsemID58squ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# ğŸ”’ XSS Robustness / Adversarial Test\n",
        "# ============================================\n",
        "import random, re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„Ù€ tokenizer Ø¬Ø§Ù‡Ø²ÙŠÙ†\n",
        "model.eval()\n",
        "\n",
        "def generate_xss_variants(xss_text):\n",
        "    \"\"\"Produce several obfuscated variants of an XSS sample\"\"\"\n",
        "    variants = []\n",
        "    t = xss_text\n",
        "\n",
        "    # 1. HTML encoding\n",
        "    variants.append(t.replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\"))\n",
        "\n",
        "    # 2. URL encoding\n",
        "    variants.append(t.replace(\"<\", \"%3C\").replace(\">\", \"%3E\"))\n",
        "\n",
        "    # 3. Mixed case in 'script'\n",
        "    variants.append(re.sub(r'script', lambda m: ''.join(\n",
        "        random.choice([c.upper(), c.lower()]) for c in m.group(0)), t, flags=re.I))\n",
        "\n",
        "    # 4. Insert random spaces\n",
        "    variants.append(re.sub(r'script', 'scr ipt', t, flags=re.I))\n",
        "\n",
        "    # 5. Break tags with comments\n",
        "    variants.append(t.replace(\"<script>\", \"<scr<!--xss-->ipt>\"))\n",
        "\n",
        "    # 6. Unicode obfuscation\n",
        "    variants.append(t.replace(\"script\", \"scr\\\\u0069pt\"))\n",
        "\n",
        "    # 7. Random encoding mix\n",
        "    mixed = t.replace(\"<\", \"%3C\").replace(\">\", \"&gt;\")\n",
        "    variants.append(mixed)\n",
        "\n",
        "    return variants\n",
        "\n",
        "# Ø®Ø° Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù€ XSS Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù…Ù† test set\n",
        "xss_samples = [x for x, y in zip(ds[\"test\"][\"raw_text\"], ds[\"test\"][\"label\"]) if y == 1]\n",
        "xss_samples = random.sample(xss_samples, min(50, len(xss_samples)))  # Ø®Ø° 50 Ø¹ÙŠÙ†Ø© ÙÙ‚Ø·\n",
        "\n",
        "# Ø¬Ù‡Ù‘Ø² Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
        "correct, total = 0, 0\n",
        "detailed_results = []\n",
        "\n",
        "for original in tqdm(xss_samples, desc=\"Testing variants\"):\n",
        "    variants = generate_xss_variants(original)\n",
        "    for v in variants:\n",
        "        inputs = tokenizer(v, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            pred = torch.argmax(outputs.logits, dim=1).item()\n",
        "        total += 1\n",
        "        correct += int(pred == 1)\n",
        "        detailed_results.append({\n",
        "            \"variant\": v,\n",
        "            \"pred\": pred\n",
        "        })\n",
        "\n",
        "acc = correct / total\n",
        "print(f\"\\nğŸ” Robustness Accuracy: {acc*100:.2f}% ({correct}/{total})\")\n",
        "\n",
        "# Ù„Ùˆ Ø¹Ø§ÙŠØ² ØªØ´ÙˆÙ Ø£Ù…Ø«Ù„Ø© ÙØ´Ù„ ÙÙŠÙ‡Ø§\n",
        "fails = [r for r in detailed_results if r[\"pred\"] == 0]\n",
        "if fails:\n",
        "    print(\"\\nâš ï¸ Some variants were not detected correctly:\")\n",
        "    for f in fails[:5]:\n",
        "        print(\"-\", f[\"variant\"][:150], \"...\")\n",
        "else:\n",
        "    print(\"\\nâœ… All variants detected successfully.\")\n"
      ],
      "metadata": {
        "id": "cFQuWOa_8vR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# ğŸ“Š XSS Robustness Visualization\n",
        "# ============================================\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# ØµÙ†Ù‘Ù Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„ØªØ­ÙˆÙŠØ± Ù…Ù† Ø§Ù„Ù†Øµ Ù†ÙØ³Ù‡\n",
        "def detect_variant_type(v):\n",
        "    if \"&lt;\" in v or \"&gt;\" in v:\n",
        "        return \"HTML Encoding\"\n",
        "    elif \"%3C\" in v or \"%3E\" in v:\n",
        "        return \"URL Encoding\"\n",
        "    elif re.search(r'scr.?ipt', v, flags=re.I):\n",
        "        if \" \" in v:\n",
        "            return \"Inserted Space\"\n",
        "        elif \"u0069\" in v:\n",
        "            return \"Unicode\"\n",
        "        elif \"!--\" in v:\n",
        "            return \"Comment Break\"\n",
        "        else:\n",
        "            return \"Mixed Case\"\n",
        "    else:\n",
        "        return \"Other\"\n",
        "\n",
        "df_robust = pd.DataFrame(detailed_results)\n",
        "df_robust[\"variant_type\"] = df_robust[\"variant\"].apply(detect_variant_type)\n",
        "df_robust[\"correct\"] = (df_robust[\"pred\"] == 1).astype(int)\n",
        "\n",
        "# Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ Ù„ÙƒÙ„ Ù†ÙˆØ¹ ØªØ­ÙˆÙŠØ±\n",
        "robust_summary = (\n",
        "    df_robust.groupby(\"variant_type\")[\"correct\"]\n",
        "    .mean()\n",
        "    .sort_values(ascending=False)\n",
        "    .reset_index()\n",
        ")\n",
        "robust_summary.columns = [\"Variant Type\", \"Accuracy\"]\n",
        "\n",
        "print(\"===== Robustness Summary by Variant Type =====\")\n",
        "print(robust_summary)\n",
        "\n",
        "# ====== Visualization ======\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(\n",
        "    data=robust_summary,\n",
        "    x=\"Accuracy\",\n",
        "    y=\"Variant Type\",\n",
        "    hue=\"Variant Type\",\n",
        "    legend=False,\n",
        ")\n",
        "plt.title(\"Model Robustness per XSS Variant Type\")\n",
        "plt.xlabel(\"Detection Accuracy\")\n",
        "plt.ylabel(\"Variant Type\")\n",
        "plt.xlim(0, 1)\n",
        "plt.show()\n",
        "\n",
        "# ====== Heatmap for overall distribution ======\n",
        "pivot_data = pd.pivot_table(\n",
        "    df_robust,\n",
        "    values=\"correct\",\n",
        "    index=\"variant_type\",\n",
        "    aggfunc=[\"mean\", \"count\"]\n",
        ").round(2)\n",
        "\n",
        "plt.figure(figsize=(6, 3))\n",
        "sns.heatmap(\n",
        "    pivot_data[\"mean\"].to_frame().T,\n",
        "    annot=True, cmap=\"YlGnBu\", cbar=False\n",
        ")\n",
        "plt.title(\"Average Detection Accuracy Heatmap\")\n",
        "plt.yticks([])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BkjWtcWD8yE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns.tolist())\n"
      ],
      "metadata": {
        "id": "iLX4rECoNa6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# Ø¹Ø¯Ø¯ Ø§Ù„ØªØ­ÙˆÙŠØ±Ø§Øª (augmentations) Ù„ÙƒÙ„ Ø¹ÙŠÙ†Ø©\n",
        "AUGMENT_PER_SAMPLE = 3\n",
        "\n",
        "# Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ­ÙˆÙŠØ± (Augmentation functions)\n",
        "def random_case_flip(text):\n",
        "    return ''.join(c.upper() if random.random() > 0.5 else c.lower() for c in text)\n",
        "\n",
        "def insert_random_spaces(text):\n",
        "    return ''.join(c + ' ' if random.random() < 0.1 else c for c in text)\n",
        "\n",
        "def inject_html_noise(text):\n",
        "    noises = [\"<!--xss-->\", \"&nbsp;\", \"&#x3C;\", \"&#x3E;\"]\n",
        "    words = text.split()\n",
        "    if not words:\n",
        "        return text\n",
        "    pos = random.randint(0, len(words)-1)\n",
        "    words.insert(pos, random.choice(noises))\n",
        "    return ' '.join(words)\n",
        "\n",
        "augmentations = [random_case_flip, insert_random_spaces, inject_html_noise]\n",
        "\n",
        "# Ø¥Ù†Ø´Ø§Ø¡ DataFrame Ø¬Ø¯ÙŠØ¯ ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø£ØµÙ„ÙŠØ© ÙˆØ§Ù„Ù…Ø­ÙˆØ±Ø©\n",
        "augmented_rows = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    for _ in range(AUGMENT_PER_SAMPLE):\n",
        "        aug_func = random.choice(augmentations)\n",
        "        new_payload = aug_func(row[\"raw_text\"])   # âœ… Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„ØµØ­ÙŠØ­\n",
        "        augmented_rows.append({\n",
        "            \"raw_text\": new_payload,\n",
        "            \"label\": row[\"label\"]\n",
        "        })\n",
        "\n",
        "df_augmented = pd.DataFrame(augmented_rows)\n",
        "\n",
        "# Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ ØªÙƒØ±Ø§Ø±Ø§Øª Ù…Ø­ØªÙ…Ù„Ø©\n",
        "df_augmented.drop_duplicates(subset=[\"raw_text\"], inplace=True)\n",
        "\n",
        "# Ø¯Ù…Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù…Ø¹ Ø§Ù„Ù…Ø­ÙˆÙ‘Ø±Ø©\n",
        "df_combined = pd.concat([df[[\"raw_text\", \"label\"]], df_augmented], ignore_index=True)\n",
        "\n",
        "# Ø­ÙØ¸ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©\n",
        "output_path = \"xss_augmented_dataset.csv\"\n",
        "df_combined.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(f\"âœ… Original samples: {len(df)}\")\n",
        "print(f\"âœ… Augmented samples: {len(df_augmented)}\")\n",
        "print(f\"âœ… Combined total: {len(df_combined)}\")\n",
        "print(f\"ğŸ’¾ Saved augmented dataset to: {output_path}\")\n"
      ],
      "metadata": {
        "id": "rbX3KslvNLzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Robust training cell: handles older/newer transformers signatures and checks labels\n",
        "from datasets import Dataset\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "import pandas as pd\n",
        "import torch\n",
        "import inspect\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# ------- Config (Ø¹Ø¯Ù‘Ù„ Ø§Ù„Ù‚ÙŠÙ… Ù„Ùˆ Ø§Ø­ØªØ¬Øª) -------\n",
        "DATA_PATH = \"xss_augmented_dataset.csv\"   # Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù„Ù‰ Ø­ÙØ¸Ù†Ø§Ù‡\n",
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 3\n",
        "LR = 2e-5\n",
        "OUTPUT_DIR = \"./results_augmented\"\n",
        "# --------------------------------------------\n",
        "\n",
        "# 0) ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù ÙˆØ§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©\n",
        "df_all = pd.read_csv(DATA_PATH)\n",
        "print(\"Columns:\", df_all.columns.tolist())\n",
        "print(\"Sample rows:\\n\", df_all.head())\n",
        "\n",
        "# 0.1) ÙØ­Øµ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù€ labels ÙÙˆØ±Ø§Ù‹\n",
        "print(\"\\nLabel distribution:\")\n",
        "print(df_all['label'].value_counts(normalize=False))\n",
        "print(df_all['label'].value_counts(normalize=True))\n",
        "\n",
        "# 0.2) ØªØ­Ù‚Ù‚ Ø³Ø±ÙŠØ¹ Ù…Ù† Ø£Ù…Ø«Ù„Ø© Ù…ØªÙ†Ø§Ù‚Ø¶Ø© (ÙˆØ¬ÙˆØ¯ 'script' Ùˆ label==0)\n",
        "mask_susp = df_all['label']==0\n",
        "mask_has_script = df_all['raw_text'].str.contains(r'(script|alert\\(|onerror=|javascript:)', case=False, na=False)\n",
        "weird = df_all[mask_susp & mask_has_script].head(5)\n",
        "if len(weird)>0:\n",
        "    print(\"\\nâš ï¸ Found examples that look like XSS but labeled 0 (showing up to 5):\")\n",
        "    display(weird[['raw_text','label']])\n",
        "else:\n",
        "    print(\"\\nNo obvious label-suspicious examples found in quick check.\")\n",
        "\n",
        "# 1) Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df_all, test_size=0.2, random_state=42, stratify=df_all[\"label\"])\n",
        "print(f\"\\nTrain samples: {len(train_df)} | Test samples: {len(test_df)}\")\n",
        "\n",
        "# 2) Tokenizer + HF Dataset\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "    return tokenizer(batch[\"raw_text\"], padding=\"max_length\", truncation=True, max_length=MAX_LEN)\n",
        "\n",
        "# create HF Datasets\n",
        "train_ds = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
        "test_ds  = Dataset.from_pandas(test_df.reset_index(drop=True))\n",
        "\n",
        "train_ds = train_ds.map(lambda ex: tokenize_fn(ex), batched=True)\n",
        "test_ds  = test_ds.map(lambda ex: tokenize_fn(ex), batched=True)\n",
        "\n",
        "# remove raw_text from inputs if you want (trainer can handle extra columns but we clean)\n",
        "train_ds = train_ds.remove_columns([c for c in train_ds.column_names if c not in (\"input_ids\",\"attention_mask\",\"label\")])\n",
        "test_ds  = test_ds.remove_columns([c for c in test_ds.column_names if c not in (\"input_ids\",\"attention_mask\",\"label\")])\n",
        "\n",
        "# rename label -> labels for Trainer compatibility\n",
        "train_ds = train_ds.rename_column(\"label\", \"labels\")\n",
        "test_ds  = test_ds.rename_column(\"label\", \"labels\")\n",
        "\n",
        "train_ds.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
        "test_ds.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
        "\n",
        "# 3) Compute class weights (optional use later)\n",
        "classes = np.unique(train_df[\"label\"])\n",
        "cw = compute_class_weight(\"balanced\", classes=classes, y=train_df[\"label\"])\n",
        "class_weights = {int(c): float(w) for c,w in zip(classes, cw)}\n",
        "print(\"\\nClass weights (train):\", class_weights)\n",
        "\n",
        "# 4) Load model (fresh classifier head)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
        "\n",
        "# 5) Prepare TrainingArguments in a robust way (filter based on signature)\n",
        "training_kwargs = dict(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    save_steps=500,\n",
        "    logging_steps=100,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE*2,\n",
        "    learning_rate=LR,\n",
        "    weight_decay=0.01,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    load_best_model_at_end=False,   # Ù†ÙØ¨Ù‚ÙŠÙ‡Ø§ False Ù„ØªÙØ§Ø¯ÙŠ ØªØ¹Ø§Ø±Ø¶ Ø§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª\n",
        "    save_total_limit=2,\n",
        "    fp16=torch.cuda.is_available(),\n",
        ")\n",
        "\n",
        "sig = inspect.signature(TrainingArguments.__init__)\n",
        "accepted = set(sig.parameters.keys()) - {\"self\",\"kwargs\"}\n",
        "filtered_kwargs = {k:v for k,v in training_kwargs.items() if k in accepted}\n",
        "\n",
        "# map eval strategy to legacy name if needed\n",
        "if \"evaluation_strategy\" not in filtered_kwargs:\n",
        "    if \"evaluate_during_training\" in accepted:\n",
        "        filtered_kwargs[\"evaluate_during_training\"] = True\n",
        "\n",
        "print(\"\\nFinal TrainingArguments keys used:\", list(filtered_kwargs.keys()))\n",
        "training_args = TrainingArguments(**filtered_kwargs)\n",
        "\n",
        "# 6) Trainer\n",
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    import numpy as np\n",
        "    from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary', pos_label=1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=test_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# 7) Start training\n",
        "print(\"\\nğŸš€ Starting training ...\")\n",
        "trainer.train()\n",
        "\n",
        "# 8) Final evaluation\n",
        "print(\"\\nğŸ“Š Final evaluation on test set:\")\n",
        "metrics = trainer.evaluate(test_ds)\n",
        "print(metrics)\n",
        "\n",
        "# 9) Save model & tokenizer\n",
        "trainer.save_model(OUTPUT_DIR + \"/final_model\")\n",
        "tokenizer.save_pretrained(OUTPUT_DIR + \"/final_model_tokenizer\")\n",
        "print(\"Saved final model to:\", OUTPUT_DIR + \"/final_model\")\n"
      ],
      "metadata": {
        "id": "J1Vk9gh1NMQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PswUiyV8UUil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WsS7Ki_ZN9Ik"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}